{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural Language Processing",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMxRrcZiYunTPmMuHENYLlO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewNewton13/Learning/blob/main/Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_b-kPLP5l0J"
      },
      "source": [
        "# Introduction to NLP Funadmentals in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKtw1d-yHb6h",
        "outputId": "fa15eb3e-bb66-479a-d986-21b56aeda311"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-d85f92d1-0f8b-116a-b3b4-c800c1869575)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY8REjnJH1ea",
        "outputId": "abf95b54-3ad2-42de-a417-7b8b072f0703"
      },
      "source": [
        "# Get helper functions\n",
        "!wget https://github.com/mrdbourke/tensorflow-deep-learning/raw/main/extras/helper_functions.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-02 14:00:53--  https://github.com/mrdbourke/tensorflow-deep-learning/raw/main/extras/helper_functions.py\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py [following]\n",
            "--2021-08-02 14:00:53--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-02 14:00:53 (96.4 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w476CCoDIG5A"
      },
      "source": [
        "# Import series of helper functions for notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dDoEUMRIbOe"
      },
      "source": [
        "# Getting the Dataset\n",
        "\n",
        "Get Kaggle NLP dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id35VXrIIiA7",
        "outputId": "4dcd0f82-7fed-4c7a-b206-f72ab2d0b5f6"
      },
      "source": [
        "# Download the dataset\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-02 14:00:55--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.128, 142.250.101.128, 142.250.141.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-08-02 14:00:55 (121 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TebFGI6yI4hM"
      },
      "source": [
        "# Unzip the data\n",
        "unzip_data('nlp_getting_started.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFp-nhW5JAl1"
      },
      "source": [
        "# Visualizing a Text Dataset\n",
        "\n",
        "Visualize, visualize, visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heaPjdeMJPKM"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "daoq1-hVaLCb",
        "outputId": "b891abf6-e49e-4442-c496-107fb12094a1"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM-JrVoiayFt"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "lteEePr3a3vt",
        "outputId": "30d30d4d-57a1-4978-cbe1-d745beef7beb"
      },
      "source": [
        "# what does the test dataframe look like?\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HelyBQv0bnAT",
        "outputId": "17ee7d40-d2d7-49d3-b904-9dd9e37b1514"
      },
      "source": [
        "# How many examples of each class are there?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O-bkQcKbu7I",
        "outputId": "e4d48a8d-62f1-4611-de95-edfa6bbede8e"
      },
      "source": [
        "# Total number of samples\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymuObSFHcR64",
        "outputId": "b68ba478-4057-448b-e56e-74c1f46485f4"
      },
      "source": [
        "# Let's visualize some random training samples\n",
        "import random\n",
        "random_index = random.randint(0,len(train_df)-5) # create random indexes\n",
        "for row in train_df_shuffled[[\"text\",\"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "We walk the plank of a sinking ship\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@Zak_Bagans pets r like part of the family. I love animals.??? The last 2 pets I had I rescued! Breaks my heart when animals are mistreated????\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "ON THE USE OF PERFORATED METAL SHEAR PANEL SFOR SEISMIC-RESISTANT APPLICATIONS http://t.co/cX5OjH2Dr4\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "The answer my friend is yelling in the wind-my latest article for http://t.co/LbMeKYphM5.Pls read and share - thanks! http://t.co/9NwAJLi9cr\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Woman electrocuted #Red #Redblood #videoclip http://t.co/9PYmM2RUWf #\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdy-6lVud0rf"
      },
      "source": [
        "# Split Data Into Training and Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqWN5KcNgsUU"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4Zyu6vBgwIw"
      },
      "source": [
        "# Use train test split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled['target'].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dFhJll-hmxY",
        "outputId": "44a06eb8-ee51-4188-b5d2-877636bb7718"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkE_Gq8XhuBN",
        "outputId": "b5afe3b1-1e50-4d56-e465-26fbd7ab097a"
      },
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd-rkLLSh2G7"
      },
      "source": [
        "# Convert Text into Numbers\n",
        "\n",
        "Models don't like words, they like numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKRqe_oYjVly",
        "outputId": "6d5dda5e-a7d5-4a9e-bf22-c27616696216"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "958M2RYWl7j2"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syyMmzyOmBf7"
      },
      "source": [
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (automatically add <00V>)\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    split=\"whitespace\",\n",
        "                                    ngrams=None, # create groups of n-words\n",
        "                                    output_mode=\"int\", # how to map tokens to words\n",
        "                                    output_sequence_length=50, # how long do you want your sequences to be\n",
        "                                    pad_to_max_tokens=True # pad with 0s  \n",
        "                                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK8i5kiOpQg1",
        "outputId": "6ed2a400-c032-431b-8362-80889b43764c"
      },
      "source": [
        "# Find the average number of tokens in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcOZxohnp26L"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words in our vocabulary\n",
        "max_length = 15 # max length our sequences will be/how many words from a tweet our model sees\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAR1uwWKqX-b"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtxs428grIm5",
        "outputId": "0813d1ec-5fe5-4de8-dbe7-486a2a9a778f"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"there's a flood in my street\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDdvNOudrS3X",
        "outputId": "09d91e7f-0f0b-4908-8bed-e89e18cdafd7"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "\\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " Pandemonium In Aba As Woman Delivers Baby Without Face (Photos) http://t.co/wRqF6U55hh\n",
            "\n",
            "Vectorized version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 502,    4, 1157,   26,  410, 1146,  469,  228,  289,  729,    1,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH8wB8sXr17t",
        "outputId": "109122cd-d554-4b6d-c3e8-d6eb0f6d664b"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in our training data\n",
        "top_5_words = words_in_vocab[:5] # get the most 5 common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least 5 common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Most common words: {top_5_words}\")\n",
        "print(f\"Least common words: {bottom_5_words}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocab: 10000\n",
            "Most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmjJko-HsXgI"
      },
      "source": [
        "# Creating an Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtFrTFlvo26x",
        "outputId": "4d18c223-da24-48b7-d622-044186da17a2"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,\n",
        "                             input_length=max_length)\n",
        "embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f2ea012b6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwoOB4Ybp3FS",
        "outputId": "f8c28b63-2777-457c-f42b-5e01fc01d160"
      },
      "source": [
        "# Get a random sentence\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "\\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn positive integers into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " @nuggets #FETTILOOTCH IS #SLANGLUCCI OPPRESSIONS GREATEST DANGER COMING SOON THE ALBUM \n",
            "https://t.co/moLL5vd8yD\n",
            "\n",
            "Embedded version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.00698618,  0.0365108 ,  0.04417353, ..., -0.04073453,\n",
              "         -0.00276176, -0.02843927],\n",
              "        [ 0.02777245, -0.02022661,  0.04938425, ..., -0.03861214,\n",
              "          0.0045853 ,  0.04564835],\n",
              "        [ 0.04065524,  0.03276226,  0.01760873, ...,  0.0222453 ,\n",
              "          0.01231786, -0.04059511],\n",
              "        ...,\n",
              "        [ 0.04451367,  0.03127616, -0.03154935, ...,  0.00902586,\n",
              "         -0.03127798, -0.00535891],\n",
              "        [ 0.04451367,  0.03127616, -0.03154935, ...,  0.00902586,\n",
              "         -0.03127798, -0.00535891],\n",
              "        [ 0.04451367,  0.03127616, -0.03154935, ...,  0.00902586,\n",
              "         -0.03127798, -0.00535891]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22G2kXIMqeKd",
        "outputId": "de535c11-3ff7-4eb7-be2b-80659b93f75d"
      },
      "source": [
        "# Check out a sigle token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.00698618,  0.0365108 ,  0.04417353, -0.04624617,  0.02750218,\n",
              "         0.02791592,  0.03263079,  0.04091332,  0.03733362, -0.03380834,\n",
              "         0.03359528, -0.0245878 , -0.01912527, -0.01275373, -0.00585026,\n",
              "        -0.04448568,  0.02613641,  0.01420064, -0.02636045, -0.04603962,\n",
              "        -0.03988938, -0.00078498,  0.02124057, -0.01608895,  0.04551783,\n",
              "         0.03513447, -0.03498001, -0.02366414, -0.03927336,  0.04608181,\n",
              "         0.00675166, -0.01391878, -0.03165009,  0.04159469,  0.01373844,\n",
              "         0.01975587,  0.01552521,  0.01734496,  0.00557522, -0.00138186,\n",
              "         0.01044982, -0.02644907, -0.02604102, -0.01043921,  0.01420405,\n",
              "        -0.0224874 , -0.00647827,  0.00362867,  0.0300725 , -0.03339206,\n",
              "        -0.02586372,  0.01088081,  0.04634395, -0.02911819,  0.02931705,\n",
              "         0.03308945,  0.02476833, -0.00609992, -0.01170794, -0.03618569,\n",
              "         0.003681  ,  0.04097647, -0.0055182 , -0.03015654, -0.01939771,\n",
              "         0.04723426, -0.02079254, -0.04758834,  0.02278353,  0.01838278,\n",
              "        -0.01888669, -0.02766601, -0.04165357, -0.04440296, -0.04486405,\n",
              "        -0.0188234 ,  0.01965285, -0.03056402,  0.00629061,  0.01014448,\n",
              "        -0.03646505,  0.01086582,  0.00027887, -0.01898955,  0.03102496,\n",
              "        -0.01049255, -0.02805719, -0.03852529, -0.02044878,  0.0049945 ,\n",
              "        -0.00974565, -0.00606178, -0.04543851, -0.02869214, -0.02957463,\n",
              "        -0.02322893,  0.00650563, -0.02351069,  0.00520319, -0.0035281 ,\n",
              "         0.0361439 , -0.03064197, -0.04907973,  0.04175097,  0.04304716,\n",
              "         0.03586816,  0.02627024, -0.02186474,  0.04984863, -0.04666331,\n",
              "         0.03757005, -0.00926112,  0.02319146, -0.02146541,  0.00296017,\n",
              "        -0.04736954,  0.02251258, -0.00815614,  0.03176248, -0.01209711,\n",
              "        -0.00925132,  0.01686925,  0.01421417, -0.03720759,  0.03715421,\n",
              "        -0.04073453, -0.00276176, -0.02843927], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " '@')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHGlvk8vq8-r"
      },
      "source": [
        "# Baseline Model - Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VifnlKir0V3",
        "outputId": "61d2a19c-9b08-431a-9020-1e7572ca1a68"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modeling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\",TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\",MultinomialNB()) # model the text\n",
        "\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WjN8CjFtznR",
        "outputId": "b7e84a17-7a2c-4ded-d91f-003106d9835a"
      },
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences,val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_CEky6lvXPD",
        "outputId": "2b2351f5-0662-41f5-d886-f3bc35267e88"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUDcabyzvjS5",
        "outputId": "c7201cf1-dab5-4201-d46d-fd3266d9a7a1"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "baseline_results = classification_report(val_labels,baseline_preds)\n",
        "print(classification_report(val_labels,baseline_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83       414\n",
            "           1       0.89      0.63      0.73       348\n",
            "\n",
            "    accuracy                           0.79       762\n",
            "   macro avg       0.82      0.78      0.78       762\n",
            "weighted avg       0.81      0.79      0.79       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p7T61vewaCD",
        "outputId": "601e0625-4842-462d-f19d-0cc67c1c7f57"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "print(precision_recall_fscore_support(val_labels,baseline_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0.74806202, 0.88617886]), array([0.93236715, 0.62643678]), array([0.83010753, 0.73400673]), array([414, 348]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8vNQFs5w7tV"
      },
      "source": [
        "# Model 1 - A Simple Dense Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leaweljjx9vW"
      },
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save tensorboard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtaPh2kBygmP"
      },
      "source": [
        "# Build model with the functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn input text into numbers\n",
        "x = embedding(x) # create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x) # create output layer, binary outputs\n",
        "model_1 = tf.keras.Model(inputs,outputs,name=\"model_1_dense\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTe7kKkpzPVN",
        "outputId": "ca200123-15f5-4e70-8d2d-d015d1c92a01"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcbxje34zQri"
      },
      "source": [
        "# Compile model_1\n",
        "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nZuRjwy0Cn4",
        "outputId": "ea92f746-baac-4755-a4e7-9a36c852e2ef"
      },
      "source": [
        "# Fit model_1 \n",
        "model_1_history = model_1.fit(train_sentences,train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name='model_1_dense')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20210802-140104\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 18ms/step - loss: 0.6094 - accuracy: 0.7003 - val_loss: 0.5387 - val_accuracy: 0.7493\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.4401 - accuracy: 0.8167 - val_loss: 0.4707 - val_accuracy: 0.7887\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3460 - accuracy: 0.8602 - val_loss: 0.4589 - val_accuracy: 0.7874\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2829 - accuracy: 0.8905 - val_loss: 0.4613 - val_accuracy: 0.7913\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2363 - accuracy: 0.9142 - val_loss: 0.4803 - val_accuracy: 0.7874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBsfEuf60V6M",
        "outputId": "896c1f41-7143-4416-e033-8eb34f1f0a4f"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences,val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.48029324412345886, 0.787401556968689]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmgB7T4t0mTw",
        "outputId": "5bca90e6-30e1-4859-c8f1-c260fe8c67de"
      },
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.36604792],\n",
              "       [0.7190115 ],\n",
              "       [0.9976572 ],\n",
              "       [0.10993525],\n",
              "       [0.1051427 ],\n",
              "       [0.9424389 ],\n",
              "       [0.92217547],\n",
              "       [0.99217916],\n",
              "       [0.966624  ],\n",
              "       [0.24869096]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFZt12pW0si_",
        "outputId": "3658941b-4b70-47f7-aacc-45888f0006aa"
      },
      "source": [
        "# Convert the prediction probabilities into label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWBTiOJp29if",
        "outputId": "8a7f061a-452c-40b8-c4c4-6e9079262007"
      },
      "source": [
        "# Calculate model 1 results\n",
        "model_1_results = classification_report(val_labels,model_1_preds)\n",
        "print(classification_report(val_labels,model_1_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.88      0.82       414\n",
            "           1       0.83      0.68      0.74       348\n",
            "\n",
            "    accuracy                           0.79       762\n",
            "   macro avg       0.80      0.78      0.78       762\n",
            "weighted avg       0.79      0.79      0.78       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPieeVOp3JsI",
        "outputId": "233a1058-17cc-40f7-e0ae-ac6eace9013a"
      },
      "source": [
        "print(baseline_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83       414\n",
            "           1       0.89      0.63      0.73       348\n",
            "\n",
            "    accuracy                           0.79       762\n",
            "   macro avg       0.82      0.78      0.78       762\n",
            "weighted avg       0.81      0.79      0.79       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH0VrGI93aUb"
      },
      "source": [
        "# Visualizing Learned Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d49x_lObY5n",
        "outputId": "aa8ebe37-4c4b-4582-e042-bf66c53833bb"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw3SJuYDbczi",
        "outputId": "91d184fc-46e6-48e2-ae4b-084374ef746f"
      },
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSDcjUS9cTf_",
        "outputId": "a7e859b3-d442-4e4e-9f32-62def1e9a074"
      },
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# These are the numerical representations of each token in our training data, which have been learned for 5 epochs\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.05520296,  0.02037858, -0.04327086, ..., -0.0003922 ,\n",
              "        -0.02446394,  0.00508966],\n",
              "       [ 0.04573279,  0.00377521,  0.00730899, ..., -0.04583199,\n",
              "         0.02332764, -0.01755452],\n",
              "       [-0.00666384, -0.01769004, -0.0324298 , ..., -0.03334329,\n",
              "        -0.0241269 , -0.00329707],\n",
              "       ...,\n",
              "       [ 0.04506094,  0.04716535,  0.04138646, ..., -0.0214006 ,\n",
              "        -0.01948127,  0.01978376],\n",
              "       [ 0.03216965, -0.02161333, -0.04416534, ..., -0.07389495,\n",
              "         0.04289224,  0.02201922],\n",
              "       [ 0.05414815, -0.05472768, -0.09555051, ..., -0.09549597,\n",
              "         0.02194124,  0.09247295]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOrB180LcnUN",
        "outputId": "a1351715-305f-4688-b453-ce56e26914d6"
      },
      "source": [
        "# Check the shape of embed weights\n",
        "embed_weights.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hrN4d2cc4QP"
      },
      "source": [
        "# Create embedding files (got this from tensorflow word embeddgins documentation)\n",
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti_9L1o_eRO5",
        "outputId": "27a98303-7e1d-45c7-a0d9-19f4612d1e03"
      },
      "source": [
        "# Download files from Colab to upload to projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1ffeb492-9109-4bc2-b9a7-1538fa3beff7\", \"vectors.tsv\", 15375906)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e1ae519f-c5e8-4ea6-96af-4ead650a269f\", \"metadata.tsv\", 80388)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIY84vbxfPyT"
      },
      "source": [
        "# Model 2 - LSTM\n",
        "\n",
        "LSTM means long short term memory (one of the most popular cells)\n",
        "\n",
        "RNN structure:\n",
        "\n",
        "'''\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output(label probability)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG4QJxXRjZok"
      },
      "source": [
        "# Create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#print(x.shape)\n",
        "#x = layers.LSTM(64, return_sequences=True)(x) # when you're stacking RNN cells together you need to set return_sequences=True\n",
        "#print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "#print(x.shape)\n",
        "#x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_2 = tf.keras.Model(inputs,outputs,name=\"model_2_LSTM\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qrpzEItkp0B",
        "outputId": "cd2ddc1c-b3e8-40d5-d37a-1cab3e73381a"
      },
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrkigIdamLUA"
      },
      "source": [
        "# Compile LSTM model\n",
        "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E31InFWTmUw7",
        "outputId": "6fe57422-408f-411d-8e54-502cd377fde6"
      },
      "source": [
        "# Fit LSTM model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name='model_2_LSTM')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20210802-140127\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 22ms/step - loss: 0.2267 - accuracy: 0.9188 - val_loss: 0.5670 - val_accuracy: 0.7782\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.1562 - accuracy: 0.9426 - val_loss: 0.5774 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.1281 - accuracy: 0.9514 - val_loss: 0.7610 - val_accuracy: 0.7822\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.1076 - accuracy: 0.9581 - val_loss: 0.9282 - val_accuracy: 0.7887\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0852 - accuracy: 0.9667 - val_loss: 0.8918 - val_accuracy: 0.7835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC5EWKyNmksc",
        "outputId": "3dc07134-2ebe-4155-e90a-d38c55de8b08"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.7539909e-02],\n",
              "       [5.4577595e-01],\n",
              "       [9.9951708e-01],\n",
              "       [1.0955870e-01],\n",
              "       [5.0001120e-04],\n",
              "       [9.9648935e-01],\n",
              "       [7.8150606e-01],\n",
              "       [9.9952435e-01],\n",
              "       [9.9938607e-01],\n",
              "       [7.2731787e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjLpjeZLmyo3",
        "outputId": "193d746d-5b2f-49c5-e490-f3362c1ad71f"
      },
      "source": [
        "# Convert model 2 pred probs to labels \n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJsbsLLgm8lH",
        "outputId": "4f330a30-3482-4b4a-eaa4-57f38c2f6512"
      },
      "source": [
        "# Model 2 results \n",
        "model_2_results = classification_report(val_labels,model_2_preds)\n",
        "print(model_2_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.84      0.81       414\n",
            "           1       0.79      0.72      0.75       348\n",
            "\n",
            "    accuracy                           0.78       762\n",
            "   macro avg       0.78      0.78      0.78       762\n",
            "weighted avg       0.78      0.78      0.78       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hb6AEHMnFzJ"
      },
      "source": [
        "# Model 3 - GRU\n",
        "\n",
        "Gated recurrent unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBSlLF0i-9c5"
      },
      "source": [
        "# Build a RNN using GRU cell\n",
        "from tensorflow.keras import layers\n",
        "input = layers.Input(shape=(1,),dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "# x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "model_3 = tf.keras.Model(inputs,outputs,name='model_3_GRU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQLF-CLLABeh",
        "outputId": "d77c3823-98fa-4b68-ab6e-3f3b3163dc5c"
      },
      "source": [
        "# Model 3 summary\n",
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,321,473\n",
            "Trainable params: 1,321,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt18dJvKA3Gq"
      },
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RvY663TBm3l",
        "outputId": "96401b62-a0b2-405a-ff3f-0fddcc26da2b"
      },
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_3_GRU')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20210802-140153\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 22ms/step - loss: 0.1504 - accuracy: 0.9451 - val_loss: 0.7351 - val_accuracy: 0.7808\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0825 - accuracy: 0.9682 - val_loss: 0.7694 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 16ms/step - loss: 0.0682 - accuracy: 0.9743 - val_loss: 0.9998 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0597 - accuracy: 0.9753 - val_loss: 1.3047 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0526 - accuracy: 0.9769 - val_loss: 1.3854 - val_accuracy: 0.7769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSn3MUHjBxlE",
        "outputId": "0df347b1-f546-4d16-f2c7-5191e82be069"
      },
      "source": [
        "# Make some predictions with GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1751665e-03],\n",
              "       [6.9717538e-01],\n",
              "       [9.9998808e-01],\n",
              "       [1.0020026e-01],\n",
              "       [4.8015463e-06],\n",
              "       [9.9966800e-01],\n",
              "       [1.2013673e-01],\n",
              "       [9.9999273e-01],\n",
              "       [9.9997830e-01],\n",
              "       [4.3648472e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGdjAKMOB6-_",
        "outputId": "dc7f26df-48b4-472d-d3b1-3c1a369c4e23"
      },
      "source": [
        "# Convert pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo-00D3zCDgx",
        "outputId": "91a5986b-89c7-4b95-a347-cd3c9ac207ee"
      },
      "source": [
        "# Create classification report\n",
        "model_3_results = classification_report(val_labels,model_3_preds)\n",
        "print(model_3_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.88      0.81       414\n",
            "           1       0.82      0.66      0.73       348\n",
            "\n",
            "    accuracy                           0.78       762\n",
            "   macro avg       0.79      0.77      0.77       762\n",
            "weighted avg       0.78      0.78      0.77       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMLRPafLCMdS"
      },
      "source": [
        "# Model 4 - Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaD2AJAvCg79"
      },
      "source": [
        "# Build a bidirectional RNN\n",
        "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "x = layers.Dense(64,activation='relu')(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "model_4 = tf.keras.Model(inputs,outputs,name='model_4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5gqLKnRDUAs",
        "outputId": "74a726f8-4697-410d-8741-f883379d846f"
      },
      "source": [
        "# Model 4 summary\n",
        "model_4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,387,137\n",
            "Trainable params: 1,387,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLCcFaj1FRKt"
      },
      "source": [
        "# Compile the model\n",
        "model_4.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU3aswKJGHXR",
        "outputId": "267e1965-426e-45a4-98b6-0fde72ce4d73"
      },
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_4_bidirectional')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20210802-140217\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 24ms/step - loss: 0.1079 - accuracy: 0.9685 - val_loss: 1.0115 - val_accuracy: 0.7651\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0510 - accuracy: 0.9777 - val_loss: 1.2153 - val_accuracy: 0.7769\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0450 - accuracy: 0.9778 - val_loss: 1.5663 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0502 - accuracy: 0.9768 - val_loss: 1.1796 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0388 - accuracy: 0.9806 - val_loss: 1.7873 - val_accuracy: 0.7756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLk7oYR_GaSs",
        "outputId": "d0ff8cb1-5e24-4ae5-be97-7cb38ceaff5a"
      },
      "source": [
        "# Make predictions\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.8741503e-04],\n",
              "       [8.1032401e-01],\n",
              "       [9.9999964e-01],\n",
              "       [2.8719366e-01],\n",
              "       [3.1810953e-07],\n",
              "       [9.9999881e-01],\n",
              "       [2.8706104e-01],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999940e-01],\n",
              "       [9.9902534e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8vnFMuGGm8n",
        "outputId": "f20f8cec-e35d-48a5-813b-432208f28b4f"
      },
      "source": [
        "# Convert pred probs to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptl_AS7uGsum",
        "outputId": "1f6afb76-4d31-4722-bc58-bfc640bc29d1"
      },
      "source": [
        "# Make classification report\n",
        "model_4_results = classification_report(val_labels,model_4_preds)\n",
        "print(model_4_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.85      0.80       414\n",
            "           1       0.79      0.69      0.74       348\n",
            "\n",
            "    accuracy                           0.78       762\n",
            "   macro avg       0.78      0.77      0.77       762\n",
            "weighted avg       0.78      0.78      0.77       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48mbxeP_G01j"
      },
      "source": [
        "# Model 5 - 1D Convolutional Neural Network for Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tunm8VJ5HISf"
      },
      "source": [
        "# Build a 1D Conv neural network for text\n",
        "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64,kernel_size=3,activation='relu')(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "x = layers.Dense(64,activation='relu')(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "model_5 = tf.keras.Model(inputs,outputs,name=\"model_5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QM8JZLeH-UX",
        "outputId": "a7b4a98d-2dcf-41c1-f0b7-469ee75c0dd5"
      },
      "source": [
        "# Model 5 summary\n",
        "model_5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 13, 64)            24640     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,308,865\n",
            "Trainable params: 1,308,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxY8njgEIdgq"
      },
      "source": [
        "# Compile the model\n",
        "model_5.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oaelaYmI0Pz",
        "outputId": "9ed5c009-51b5-476f-f748-5f1716326249"
      },
      "source": [
        "# Fit model 5 \n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_5_conv_1d')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_conv_1d/20210802-140302\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 31s 21ms/step - loss: 0.1431 - accuracy: 0.9545 - val_loss: 0.8352 - val_accuracy: 0.7677\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0817 - accuracy: 0.9679 - val_loss: 0.9625 - val_accuracy: 0.7625\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 16ms/step - loss: 0.0624 - accuracy: 0.9749 - val_loss: 1.0959 - val_accuracy: 0.7572\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0503 - accuracy: 0.9787 - val_loss: 1.2152 - val_accuracy: 0.7651\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0441 - accuracy: 0.9799 - val_loss: 1.2489 - val_accuracy: 0.7585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8dvrlDMJGRI",
        "outputId": "865c3d79-d7cc-482c-be9d-e422a077b297"
      },
      "source": [
        "# Make predictions \n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.9831444e-02],\n",
              "       [6.3057148e-01],\n",
              "       [9.9985635e-01],\n",
              "       [5.3393073e-02],\n",
              "       [4.4089729e-06],\n",
              "       [9.9972767e-01],\n",
              "       [9.6760899e-01],\n",
              "       [9.9964941e-01],\n",
              "       [9.9999642e-01],\n",
              "       [9.7397059e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJdSG-KkSdWs",
        "outputId": "4ac4da44-d466-4065-c1f0-d4bff267bb73"
      },
      "source": [
        "# Convert pred probs to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qziuHzpESmUr",
        "outputId": "64ed5b23-0dd6-4ae8-eaeb-c36dfc252479"
      },
      "source": [
        "# Make classification report\n",
        "model_5_results = classification_report(val_labels,model_5_preds)\n",
        "print(model_5_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.84      0.79       414\n",
            "           1       0.77      0.67      0.72       348\n",
            "\n",
            "    accuracy                           0.76       762\n",
            "   macro avg       0.76      0.75      0.75       762\n",
            "weighted avg       0.76      0.76      0.76       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IHobqmASywR",
        "outputId": "41cfccfe-f27a-40bf-e335-34277de8c707"
      },
      "source": [
        "print(baseline_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83       414\n",
            "           1       0.89      0.63      0.73       348\n",
            "\n",
            "    accuracy                           0.79       762\n",
            "   macro avg       0.82      0.78      0.78       762\n",
            "weighted avg       0.81      0.79      0.79       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb2PPJkwTB3_"
      },
      "source": [
        "# Model 6 - Pretrained Feature Extractor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2gdLKuiT2hd",
        "outputId": "b7668272-f426-48ea-d543-5b89f7a874c1"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence])\n",
        "print(embed_samples[0][:50]), embed_samples.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157024  0.02485911  0.02878048 -0.01271502  0.0397154   0.08827759\n",
            "  0.02680984  0.05589837 -0.01068729 -0.00597293  0.00639323 -0.01819519\n",
            "  0.00030816  0.09105889  0.05874645 -0.03180628  0.01512473 -0.05162928\n",
            "  0.00991364 -0.06865346 -0.04209306  0.02678978  0.03011007  0.00321067\n",
            " -0.00337968 -0.04787357  0.02266722 -0.00985927 -0.04063614 -0.01292094\n",
            " -0.04666385  0.056303   -0.03949257  0.00517688  0.02495825 -0.07014439\n",
            "  0.02871507  0.04947682 -0.00633977 -0.08960193  0.02807119 -0.00808361\n",
            " -0.01360602  0.05998649 -0.10361786 -0.05195374  0.00232955 -0.02332531\n",
            " -0.03758105  0.0332773 ], shape=(50,), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, TensorShape([1, 512]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAQwhCKnWOFj"
      },
      "source": [
        "# Create keras layer using pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],\n",
        "                                        trainable=False,\n",
        "                                        dtype=tf.string,\n",
        "                                        name='USE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkwroCiwXwmQ"
      },
      "source": [
        "# Create model using Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "                               sentence_encoder_layer,\n",
        "                               layers.Dense(64,activation='relu'),\n",
        "                               layers.Dense(1,activation='sigmoid',name='output_layer')\n",
        "], name='model_6_USE')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkCa1hmyYHrn"
      },
      "source": [
        "# Compile model\n",
        "model_6.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PakZywouYM_z",
        "outputId": "4fb0ae7d-e599-43f4-9dc9-b383d6a03cba"
      },
      "source": [
        "# Check model summary\n",
        "model_6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfESMuSqYPS9",
        "outputId": "b69a554c-5d58-4b9b-8021-79af1c676608"
      },
      "source": [
        "# Train a classifier on top of USE pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_6_USE')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_6_USE/20210802-140445\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 25ms/step - loss: 0.5083 - accuracy: 0.7827 - val_loss: 0.4463 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.4139 - accuracy: 0.8164 - val_loss: 0.4437 - val_accuracy: 0.8071\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.4015 - accuracy: 0.8222 - val_loss: 0.4316 - val_accuracy: 0.8176\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3927 - accuracy: 0.8270 - val_loss: 0.4269 - val_accuracy: 0.8150\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3852 - accuracy: 0.8298 - val_loss: 0.4284 - val_accuracy: 0.8123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ncyo16UYnZM",
        "outputId": "10b5e240-3508-4819-8cbc-441025c69028"
      },
      "source": [
        "# Make pred probs\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16474931],\n",
              "       [0.7591822 ],\n",
              "       [0.9887643 ],\n",
              "       [0.19757292],\n",
              "       [0.70069414],\n",
              "       [0.6976702 ],\n",
              "       [0.98347545],\n",
              "       [0.97658074],\n",
              "       [0.9360229 ],\n",
              "       [0.07946248]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHrTMBJLY4dz",
        "outputId": "ba864785-ff28-4e4a-ea42-aad7d0ec131d"
      },
      "source": [
        "# Convert pred probs to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAiT-3mqY-6Z",
        "outputId": "9299f91b-0501-43cc-d96e-7faac7ac906b"
      },
      "source": [
        "# Make classification report\n",
        "model_6_results = classification_report(val_labels,model_6_preds)\n",
        "print(model_6_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84       414\n",
            "           1       0.85      0.72      0.78       348\n",
            "\n",
            "    accuracy                           0.81       762\n",
            "   macro avg       0.82      0.81      0.81       762\n",
            "weighted avg       0.82      0.81      0.81       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hndn52rZH3u",
        "outputId": "745266a1-360f-4364-aaf6-cc694901c08d"
      },
      "source": [
        "print(baseline_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83       414\n",
            "           1       0.89      0.63      0.73       348\n",
            "\n",
            "    accuracy                           0.79       762\n",
            "   macro avg       0.82      0.78      0.78       762\n",
            "weighted avg       0.81      0.79      0.79       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjmiLHNiZNgT"
      },
      "source": [
        "# Model 7 - 10% Data with Pretrained Feature Extractor\n",
        "\n",
        "Replicate model 6 but train on only 10% of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g6WNfoCvL3z",
        "outputId": "64d3da0d-0667-47d6-db70-b4cd85846609"
      },
      "source": [
        "# Create subsets of 10% data\n",
        "train_10_percent_split = int(0.1 *len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
        "len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(685, 685)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8zgC8EubIMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ad7487-1286-481d-ba1b-f1a7985788ec"
      },
      "source": [
        "# Let's build a model the same as model_6 using tf.keras.clone_model\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics='accuracy')\n",
        "\n",
        "model_7.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WuHiZ7rsXeM",
        "outputId": "d19a5751-3209-4cf3-981c-7cd628571bf4"
      },
      "source": [
        "# Fit the model to the 10% training data\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_7_10_percent_correct')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_7_10_percent_correct/20210802-140506\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 117ms/step - loss: 0.6612 - accuracy: 0.6978 - val_loss: 0.6401 - val_accuracy: 0.7165\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.5887 - accuracy: 0.7854 - val_loss: 0.5865 - val_accuracy: 0.7598\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.5187 - accuracy: 0.8073 - val_loss: 0.5331 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.4594 - accuracy: 0.8204 - val_loss: 0.5055 - val_accuracy: 0.7743\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.4185 - accuracy: 0.8394 - val_loss: 0.4901 - val_accuracy: 0.7808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yXeyeGls1Pw",
        "outputId": "301593e2-d0c2-41c9-f2a7-ab0fc9ed843a"
      },
      "source": [
        "# Make predictions \n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24908693],\n",
              "       [0.6004918 ],\n",
              "       [0.905458  ],\n",
              "       [0.39113522],\n",
              "       [0.57439494],\n",
              "       [0.69722426],\n",
              "       [0.8768455 ],\n",
              "       [0.7868826 ],\n",
              "       [0.8594954 ],\n",
              "       [0.15206312]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP1HrAYstABQ",
        "outputId": "24c983af-30ea-4791-98df-39ba1528df53"
      },
      "source": [
        "# Convert pred probs to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKVRbVWstFlR",
        "outputId": "a4d1b356-794e-4c52-8237-1c35334117d1"
      },
      "source": [
        "# Make classification report\n",
        "model_7_results = classification_report(val_labels,model_7_preds)\n",
        "print(model_7_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.84      0.81       414\n",
            "           1       0.79      0.71      0.75       348\n",
            "\n",
            "    accuracy                           0.78       762\n",
            "   macro avg       0.78      0.78      0.78       762\n",
            "weighted avg       0.78      0.78      0.78       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aet2h97tMVu",
        "outputId": "95ec4a7c-cbf9-4377-a542-0691e984ea39"
      },
      "source": [
        "print(model_6_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84       414\n",
            "           1       0.85      0.72      0.78       348\n",
            "\n",
            "    accuracy                           0.81       762\n",
            "   macro avg       0.82      0.81      0.81       762\n",
            "weighted avg       0.82      0.81      0.81       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNa97DyYtXiD",
        "outputId": "ab56b200-5a4f-4aa2-b0ab-1c4cc3e098ed"
      },
      "source": [
        "print(baseline_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83       414\n",
            "           1       0.89      0.63      0.73       348\n",
            "\n",
            "    accuracy                           0.79       762\n",
            "   macro avg       0.82      0.78      0.78       762\n",
            "weighted avg       0.81      0.79      0.79       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqFkn58w4uS"
      },
      "source": [
        "# Comparing the Performances "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAdL86JbyuKu"
      },
      "source": [
        "# Uploading our model training logs to tensboard.dev\n",
        "!tensorboard dev upload --logdir ./model_logs/ \\\n",
        "  --name 'Comparing NLP Model Results' \\\n",
        "  --description 'Comparing multiple different types of model architectures on the Kaggle Tweets text classification dataset.' \\\n",
        "  --one_shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4q8GnY-zAYd"
      },
      "source": [
        "# Saving and Loading a Trained Model\n",
        "\n",
        "Two main formats for saving a model:\n",
        "1. The HDF5 format\n",
        "2. The 'SavedModel' format (default when using TensorFlow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn_s1-R-2XFO"
      },
      "source": [
        "# Save model 6 to hdf5 format\n",
        "model_6.save('model_6.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boiFOtdU7pEh"
      },
      "source": [
        "import tensorflow_hub as hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqe4UglT7PAO"
      },
      "source": [
        "# Load model with custom Hub Layer (required with HDF5 format)\n",
        "loaded_model_6 = tf.keras.models.load_model('model_6.h5', \n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzV1e0Zm75ti",
        "outputId": "66158a1f-46bc-4216-f4f3-ba3446b57a84"
      },
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences,val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4284 - accuracy: 0.8123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42842137813568115, 0.8123359680175781]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o5YUTSs8AJI",
        "outputId": "ff246dd4-6db0-4fa2-9fc9-ea4e56781ed2"
      },
      "source": [
        "print(model_6_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84       414\n",
            "           1       0.85      0.72      0.78       348\n",
            "\n",
            "    accuracy                           0.81       762\n",
            "   macro avg       0.82      0.81      0.81       762\n",
            "weighted avg       0.82      0.81      0.81       762\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7G0_gm08BDK",
        "outputId": "e13b7f95-8076-4b0c-8024-91062f44a5c7"
      },
      "source": [
        "# Save model 6 to SavedModel format\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU0zD3_j8WLB"
      },
      "source": [
        "# Load in a model from SavedModel format\n",
        "loaded_model_6_SavedModel_format = tf.keras.models.load_model('model_6_SavedModel_format')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5NjYMOE8nuB",
        "outputId": "619661ca-be0b-4e38-a71d-42cc4b7fa8c3"
      },
      "source": [
        "# Evaluate the loaded model\n",
        "loaded_model_6_SavedModel_format.evaluate(val_sentences,val_labels) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 10ms/step - loss: 0.4284 - accuracy: 0.8123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42842137813568115, 0.8123359680175781]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPTiELVn8zF5"
      },
      "source": [
        "# Finding the Most Wrong Predictions\n",
        "Which predictions were very confident but still wrong?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G10paw2j-Kp4",
        "outputId": "bae3018c-5140-46a0-ffb3-50f73e45b410"
      },
      "source": [
        "# Download a pretrained model from google storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-02 14:05:42--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.141.128, 142.251.2.128, 74.125.137.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M  34.2MB/s    in 16s     \n",
            "\n",
            "2021-08-02 14:05:58 (56.2 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8Ibt7Ho-nuO",
        "outputId": "47216a88-3edd-44c0-b005-13d41d1b3788"
      },
      "source": [
        "# Import previsouly trained model from google storage\n",
        "model_6_pretrained = tf.keras.models.load_model('08_model_6_USE_feature_extractor')\n",
        "model_6_pretrained.evaluate(val_sentences,val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBb2Pm0P-1zI",
        "outputId": "546c0f96-e745-4b63-fa1a-c0061e5e1f7c"
      },
      "source": [
        "# Make predictions with the loaded model\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "CSG6TIf59U-Z",
        "outputId": "bf91ae45-39f8-458b-92a5-b4a2c2227d0b"
      },
      "source": [
        "# Create a DataFrame with validation sentences & labels and best performing model predictions\n",
        "val_df = pd.DataFrame({'text':val_sentences,'target':val_labels,\n",
        "                       'pred':model_6_pretrained_preds,\n",
        "                       'pred_prob':tf.squeeze(model_6_pretrained_pred_probs)})\n",
        "val_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988749\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.196229\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.707808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "PaaB1E8P_cIw",
        "outputId": "a30e73fb-3b24-47ef-a080-e4fee679d67e"
      },
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df['target']!=val_df['pred']].sort_values('pred_prob',ascending=False)\n",
        "most_wrong[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.814816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.810840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.803122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Air Group is here to the rescue! We have 24/7 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.910196\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.876982\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.852300\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.835454\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.827213\n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.814816\n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   0.810840\n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.803122\n",
              "119  @freefromwolves GodsLove &amp; #thankU brother...       0   1.0   0.766901\n",
              "344  Air Group is here to the rescue! We have 24/7 ...       0   1.0   0.766625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "y0dU5HxRADMd",
        "outputId": "630ccdf6-bf14-43d2-b964-d7a366c3e5de"
      },
      "source": [
        "most_wrong[:-10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>VICTORINOX SWISS ARMY DATE WOMEN'S RUBBER MOP ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.080426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>Next May I'll be free...from school from oblig...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>@BoyInAHorsemask its a panda trapped in a dogs...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>@reriellechan HE WAS THE LICH KING'S FIRST CAS...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>'The way you move is like a full on rainstorm ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.069671</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.910196\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.876982\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.852300\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.835454\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.827213\n",
              "..                                                 ...     ...   ...        ...\n",
              "486  VICTORINOX SWISS ARMY DATE WOMEN'S RUBBER MOP ...       1   0.0   0.080426\n",
              "361  Next May I'll be free...from school from oblig...       1   0.0   0.078982\n",
              "40   @BoyInAHorsemask its a panda trapped in a dogs...       1   0.0   0.071388\n",
              "352  @reriellechan HE WAS THE LICH KING'S FIRST CAS...       1   0.0   0.071257\n",
              "681  'The way you move is like a full on rainstorm ...       1   0.0   0.069671\n",
              "\n",
              "[130 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZiPu4IwAY_U",
        "outputId": "e37f2f8a-47da-4baf-d3cd-af1288cc2ea8"
      },
      "source": [
        "# Check the false positives (model predicted 1 ehn should've been 0)\n",
        "for row in most_wrong[:10].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0, Pred: 1.0, Prob: 0.9101957678794861\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8769821524620056\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8523000478744507\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8354544639587402\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8272132277488708\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8148158192634583\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8108397126197815\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8031217455863953\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.766900897026062\n",
            "Text:\n",
            "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7666252851486206\n",
            "Text:\n",
            "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79OjrzDyCQKs",
        "outputId": "da94fad7-f6f2-4ad1-abd1-95c718b9bddc"
      },
      "source": [
        "# Check the false negatives (model predicted 1 ehn should've been 0)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 1, Pred: 0.0, Prob: 0.06730346381664276\n",
            "Text:\n",
            "@DavidVonderhaar At least you were sincere ??\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.055075809359550476\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05460338667035103\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.054597001522779465\n",
            "Text:\n",
            "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.049637261778116226\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.043918490409851074\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04208684340119362\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03899793699383736\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.038949452340602875\n",
            "Text:\n",
            "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03718579187989235\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8nyP85MC1ER"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBqcfQleD06B"
      },
      "source": [
        "# Make Predictions on the Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf1zyqNVD3l8",
        "outputId": "1aba35e5-67e6-49e0-c280-36fc318a1588"
      },
      "source": [
        "# Making predictions on test dataset and visualizing them\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences,10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample]))\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print('----\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred: 0, Prob: 0.11581898480653763\n",
            "Text:\n",
            "@KDonhoops Sure! Meek Mill accused Drake of not writing his own raps. Drake responds w/ obliteration of Meek's career. #OldFolkExplainStuff\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.9585182666778564\n",
            "Text:\n",
            "Protesters mark year since fatal police shooting in Wal-Mart (from @AP) http://t.co/3KbeJGmj0d\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.4263988137245178\n",
            "Text:\n",
            ".@ArneJungjohann #Energiewende is directly responsible for the collapse in energy value. http://t.co/NxvjPj610W\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.8669036626815796\n",
            "Text:\n",
            "RT Saginaw - Police sketches of 2 'persons of interest' in Saginaw arson http://t.co/a2tZJ07nId http://t.co/LvtP5MHjaG\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.06657341867685318\n",
            "Text:\n",
            "I'm just not a relationship person. That's why when I have a crush on someone I always think they're not going to feel the same way\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 1, Prob: 0.9721087217330933\n",
            "Text:\n",
            "[The Guardian] Islamic State claims suicide bombing at Saudi Arabian mosque http://t.co/tqvPUSaFJQ\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.03183571621775627\n",
            "Text:\n",
            "How would you like to be remembered? ÛÓ On how i survived big achievements and what i really am. http://t.co/X7r2LNjsh8\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.051515255123376846\n",
            "Text:\n",
            "Top link: Reddit's new content policy goes into effect many horrible subreddits banned or quarantined http://t.co/FEpjk1wEjD\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.06994525343179703\n",
            "Text:\n",
            "One Direction Is my pick for http://t.co/q2eBlOKeVE Fan Army #Directioners http://t.co/eNCmhz6y34 x1415\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.12842002511024475\n",
            "Text:\n",
            "Today we played mini golf in the rain I was called pretty by a creepy old guy and pretended we didn't speak English to get out of trouble\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoDJ1x8aEMXe",
        "outputId": "e63004b8-a0a9-4ea9-d8e9-7f21ee72c5ce"
      },
      "source": [
        "# Predict on a random tweet\n",
        "sample_tweet = 'I think it’s time to hit the gas station and get a monster.'\n",
        "sample_prediction = model_6_pretrained.predict([sample_tweet])\n",
        "sample_prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08432701]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo-K1TWEFwwW",
        "outputId": "fbf9fac1-0c69-4798-eefe-2e1b503d6f36"
      },
      "source": [
        "sample_tweet_2 = 'We have confirmed an 8th tornado from the July 29th event. This one occurred in Slatington,PA (Lehigh County) and is rated an EF0 with peak winds up to 85 mph. More details later. #pawx'\n",
        "sample_2_prediction = model_6_pretrained.predict([sample_tweet_2])\n",
        "sample_2_prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9464545]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8YbEApaGW4G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvernJ5gHAbm"
      },
      "source": [
        "# The Speed/Score Tradeoff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5DUMbXDHEgc"
      },
      "source": [
        "# Let's make a function to measure the time of prediction\n",
        "import time\n",
        "def pred_timer(model,samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples) # make predictions\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time - start_time # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(samples)\n",
        "  return total_time, time_per_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvNhCi8fH_nQ",
        "outputId": "6da3a933-a80b-4526-e699-e381cf9fe784"
      },
      "source": [
        "# Calculate time per pred for transfer learning model on a GPU\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6_pretrained, val_sentences)\n",
        "\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.22698233299996673, 0.00029787707742777783)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7bLa19sINIU",
        "outputId": "5bd8b460-eb4a-441d-8e9b-8fc083a16b2b"
      },
      "source": [
        "# Calculate our baseline model times per pred on a GPU\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.018842520000021068, 2.4727716535460718e-05)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "u9FWsYAaJd4Q",
        "outputId": "5bbf4669-5124-4d26-d53f-46bc93a5d4be"
      },
      "source": [
        "# Convert baseline results into a DataFrame\n",
        "baseline_results_dict = classification_report(val_labels,baseline_preds,output_dict=True)\n",
        "baseline_results_df = pd.DataFrame(baseline_results_dict).transpose()\n",
        "baseline_results_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.748062</td>\n",
              "      <td>0.932367</td>\n",
              "      <td>0.830108</td>\n",
              "      <td>414.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.886179</td>\n",
              "      <td>0.626437</td>\n",
              "      <td>0.734007</td>\n",
              "      <td>348.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.792651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.817120</td>\n",
              "      <td>0.779402</td>\n",
              "      <td>0.782057</td>\n",
              "      <td>762.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "      <td>762.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              precision    recall  f1-score     support\n",
              "0              0.748062  0.932367  0.830108  414.000000\n",
              "1              0.886179  0.626437  0.734007  348.000000\n",
              "accuracy       0.792651  0.792651  0.792651    0.792651\n",
              "macro avg      0.817120  0.779402  0.782057  762.000000\n",
              "weighted avg   0.811139  0.792651  0.786219  762.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "wq8EFJA7Ieaj",
        "outputId": "d375eb4f-8881-4e60-fb08-351b66be8397"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(baseline_time_per_pred,baseline_results_df['f1-score'],label='baseline')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-091ac12e7859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_time_per_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbaseline_results_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1-score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'baseline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[0;32m-> 2816\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2817\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2818\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4389\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4391\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIpWHxgoJUI_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}